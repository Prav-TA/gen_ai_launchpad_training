{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a6adb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from typing import List, TypedDict, Literal\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain import hub\n",
    "from PIL import Image \n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574ee40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "os.environ['LANGSMITH_API_KEY'] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dae604",
   "metadata": {},
   "source": [
    "#### Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93350ccb",
   "metadata": {},
   "source": [
    "##### Chat model : NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e2d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"NVIDIA_API_KEY\"):\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1eb4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"meta/llama3-70b-instruct\", model_provider=\"nvidia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6035f76",
   "metadata": {},
   "source": [
    "##### Embedding model : NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaf3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"NVIDIA_API_KEY\"):\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b350d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = NVIDIAEmbeddings(model=\"NV-Embed-QA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a261c",
   "metadata": {},
   "source": [
    "##### Vector Store : InMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88079a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b166a7a",
   "metadata": {},
   "source": [
    "##### RAG chain pipeline with query analysis using langGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d127574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_characters: 43130\n",
      "Split the blog post into 66 chunks\n",
      "Total embeddings added to vector store: 66\n",
      "Response: Task decomposition is the process of breaking down a complicated task into smaller and simpler steps. It involves transforming big tasks into multiple manageable tasks, making it easier to plan and execute. This can be done through various methods, including simple prompting, task-specific instructions, or human inputs.\n",
      "{'analyze_query': {'query': Search(query='Task Decomposition', section='beginning')}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='c1ddf568-cb0d-439f-b1c7-661e47ec72eb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585, 'section': 'beginning'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='69762773-c0f8-4ba3-a1e5-834b771fca5b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585, 'section': 'beginning'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='f4186f41-c2c6-4ba5-98d3-c66b6087b650', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192, 'section': 'beginning'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='18c66af4-2840-4cac-a8be-34f63be63631', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192, 'section': 'beginning'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. This technique helps agents or models to plan ahead and understand the individual steps involved in completing a task. It can be achieved through various methods, including simple prompting, task-specific instructions, or human inputs.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the blog post using WebBaseLoader\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-content\", \"post-title\", \"post-header\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "assert len(docs) == 1\n",
    "print(f\"Total_characters: {len(docs[0].page_content)}\")\n",
    "\n",
    "# Split the blog post into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Split the blog post into {len(all_splits)} chunks\")\n",
    "\n",
    "# Add metadata to each chunk\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for idx, doc in enumerate(all_splits):\n",
    "    if idx < third:\n",
    "        doc.metadata[\"section\"] = \"beginning\"\n",
    "    elif idx < third * 2:\n",
    "        doc.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        doc.metadata[\"section\"] = \"end\"\n",
    "\n",
    "# Add the chunks to the vector store\n",
    "document_ids = vector_store.add_documents(all_splits)\n",
    "print(\"Total embeddings added to vector store:\", len(document_ids))\n",
    "\n",
    "# Define search schema\n",
    "class Search(BaseModel):\n",
    "    query: str = Field(..., description=\"Search query to run.\")\n",
    "    section: Literal[\"beginning\", \"middle\", \"end\"] = Field(\n",
    "        ..., description=\"Section to query.\"\n",
    "    )  # Field(...) says this is a required field # Literal is a type alias that represents a fixed set of values\n",
    "\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define state\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Define analyze_query node\n",
    "def analyze_query(state: State):\n",
    "\n",
    "   # Custom prompt for structured query extraction\n",
    "    system_msg = (\n",
    "        \"You are a helpful assistant that extracts structured data from questions. \"\n",
    "        \"Given a user's question, extract the search query and whether the answer should be \"\n",
    "        \"from the beginning, middle, or end of a document. \"\n",
    "        \"Respond strictly in this JSON format:\\n\"\n",
    "        '{ \"query\": \"<search terms>\", \"section\": \"beginning|middle|end\" }'\n",
    "        \"Always say 'thanks for asking!' at the end of the answer.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_msg),\n",
    "        HumanMessage(content=state[\"question\"]),\n",
    "    ]\n",
    "\n",
    "    # Now bind the LLM with only the schema (not a prompt)\n",
    "    structured_llm = llm.with_structured_output(schema = Search)\n",
    "    query = structured_llm.invoke(messages)\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "# Define retrieve node\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query.query,\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query.section,\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# Define generate node\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Build LangGraph\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Run the graph \n",
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(\"Response:\",response[\"answer\"])\n",
    "\n",
    "\n",
    "# Graph stream in steps\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e14f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
